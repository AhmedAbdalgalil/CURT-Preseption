{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb826e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "prescription intializatin.. Done\n"
     ]
    }
   ],
   "source": [
    "#%time\n",
    "import numpy as np\n",
    "import numpy\n",
    "import torch       \n",
    "import torch.nn as nn  \n",
    "from PIL import Image \n",
    "import torchvision.transforms as transforms   # for transforming images into tensors \n",
    "import cv2\n",
    "from PIL import Image as im\n",
    "from ultralytics import YOLO\n",
    "#yolo initialization\n",
    "PATH_load_Yolo=\"/home/ahmed/CondaWorkSpace/Ahmeddataset/YOLOV8_CURT/best.pt\"\n",
    "model = YOLO(PATH_load_Yolo)  # load an custom model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device: ',device)\n",
    "\n",
    "#KeyPoint model initialization\n",
    "\n",
    "PATH_load_keypoints=\"/home/ahmed/CondaWorkSpace/Ahmeddataset/dataset_k/models/RESNE_input30x30.1.pt\"\n",
    "\n",
    "# convolution block with BatchNormalization\n",
    "def ConvBlock(in_channels, out_channels):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "             nn.BatchNorm2d(out_channels),\n",
    "             nn.ReLU(inplace=True)\n",
    "             #MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "             ]\n",
    "    return nn.Sequential(*layers)\n",
    "class ResNet_insize30(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.res1 = nn.Sequential(ConvBlock(64, 64), ConvBlock(64, 64))\n",
    "        self.res2 = nn.Sequential(ConvBlock(64, 128), ConvBlock(128, 128))\n",
    "        self.res3 = nn.Sequential(ConvBlock(128, 256), ConvBlock(256, 256))\n",
    "        self.res4 = nn.Sequential(ConvBlock(256, 512), ConvBlock(512, 512))\n",
    "        self.conv2=ConvBlock(64, 128)\n",
    "        self.conv3=ConvBlock(128, 256)\n",
    "        self.conv4=ConvBlock(256, 512)\n",
    "        self.classifier = nn.Sequential(\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512*30*30, num_classes))\n",
    "        \n",
    "    def forward(self, xb): # xb is the loaded batch\n",
    "        out = self.conv1(xb)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.res2(out) + self.conv2(out)       \n",
    "        out = self.res3(out) + self.conv3(out)  \n",
    "        out = self.res4(out) + self.conv4(out)  \n",
    "        out = self.classifier(out)\n",
    "        return out \n",
    "model_key = ResNet_insize30(3, 14).to(device=device)\n",
    "model_key.load_state_dict(torch.load(PATH_load_keypoints))\n",
    "print(\"prescription intializatin.. Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "051ddc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"YOLOV8_CURT/4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f607e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Yellows, 2 Blues, 6.9ms\n",
      "Speed: 12.5ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_points_list: [[1423, 794, 1411, 823, 1430, 820, 1407, 845, 1431, 839, 1402, 862, 1439, 862], [512, 785, 504, 807, 522, 805, 503, 830, 526, 825, 500, 849, 533, 843], [1206, 675, 1200, 686, 1210, 685, 1200, 694, 1212, 692, 1196, 706, 1214, 705], [819, 675, 815, 685, 823, 684, 814, 695, 825, 693, 813, 704, 828, 702]]\n",
      "cones_labels: [0.0, 1.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#%time\n",
    "\n",
    "# loud cones into a singel batch\n",
    "results = model(img)[0]\n",
    "cones_images= [img[int(box[1]):int(box[3]), int(box[0]):int(box[2])] for box in results.boxes.xyxy]\n",
    "cones_labels= results.boxes.cls.tolist()\n",
    "img_batch=[]\n",
    "cone_img_shapes=[]\n",
    "def HWC2CHW(img):\n",
    "    data = im.fromarray(img)\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    tensor = to_tensor(data)\n",
    "    return tensor.numpy()\n",
    "counter=0\n",
    "for cone_img in cones_images:\n",
    "    cone_img_shapes.append(cone_img.shape)\n",
    "    cone_img = cv2.resize(cone_img, (30, 30)) \n",
    "    img_batch.append(HWC2CHW(cone_img))\n",
    "    counter=counter+1\n",
    "img_batch=numpy.array(img_batch)\n",
    "img_batch=torch.from_numpy(img_batch)\n",
    "\n",
    "# key points  detection mode\n",
    "key_points = model_key(img_batch.to(device=device))\n",
    "# reconstract the real size images\n",
    "def key_point_size_transform(p,image_out_input_X,image_out_input_Y,image_size_out_X, image_size_out_Y):\n",
    "    counter=0\n",
    "    for p_elemrnt in p:\n",
    "        if(counter%2):\n",
    "            p[counter]=round(p_elemrnt*(image_size_out_Y/image_out_input_Y))\n",
    "        else:\n",
    "            p[counter]=round(p_elemrnt*(image_size_out_X/image_out_input_X))\n",
    "        counter=counter+1\n",
    "    return p\n",
    "\n",
    "key_points_list=[]\n",
    "counter=0\n",
    "for key_point in key_points:\n",
    "    key_points_list.append(key_point_size_transform(key_point.tolist(),\n",
    "                                                    30 ,30 ,cone_img_shapes[counter][1],\n",
    "                                                    cone_img_shapes[counter][0]))\n",
    "    counter=counter+1\n",
    "\n",
    "    \n",
    "# add  offset to refere the cones images to the input image    \n",
    "counter=0\n",
    "for key_point in key_points_list:\n",
    "    #offset\n",
    "    X_offset=results.boxes.xyxy[counter][0]\n",
    "    Y_offset=results.boxes.xyxy[counter][1]\n",
    "    #\n",
    "    key_points_list[counter][0]=int(key_point[0]+X_offset)\n",
    "    key_points_list[counter][1]=int(key_point[1]+Y_offset)\n",
    "    key_points_list[counter][2]=int(key_point[2]+X_offset)\n",
    "    key_points_list[counter][3]=int(key_point[3]+Y_offset)\n",
    "    key_points_list[counter][4]=int(key_point[4]+X_offset)\n",
    "    key_points_list[counter][5]=int(key_point[5]+Y_offset)\n",
    "    key_points_list[counter][6]=int(key_point[6]+X_offset)\n",
    "    key_points_list[counter][7]=int(key_point[7]+Y_offset)\n",
    "    key_points_list[counter][8]=int(key_point[8]+X_offset)\n",
    "    key_points_list[counter][9]=int(key_point[9]+Y_offset)\n",
    "    key_points_list[counter][10]=int(key_point[10]+X_offset)\n",
    "    key_points_list[counter][11]=int(key_point[11]+Y_offset)\n",
    "    key_points_list[counter][12]=int(key_point[12]+X_offset)\n",
    "    key_points_list[counter][13]=int(key_point[13]+Y_offset)\n",
    "    counter=counter+1\n",
    "    \n",
    "    \n",
    "#important notes:\n",
    "# key_points_list contains now list of lists where every list are 14 key point for a singel cone\n",
    "# cones_labels contaions list of cones labels\n",
    "# key points is [top,mid_L_top ,mid_R_top ,mid_L_bot,mid_R_bot , bot_L, bot_R ]\n",
    "\n",
    "\n",
    "\n",
    "print(\"key_points_list:\",key_points_list)\n",
    "print(\"cones_labels:\",cones_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e166a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1423, 794), (1411, 823), (1430, 820), (1407, 845), (1431, 839), (1402, 862), (1439, 862)], [(512, 785), (504, 807), (522, 805), (503, 830), (526, 825), (500, 849), (533, 843)], [(1206, 675), (1200, 686), (1210, 685), (1200, 694), (1212, 692), (1196, 706), (1214, 705)], [(819, 675), (815, 685), (823, 684), (814, 695), (825, 693), (813, 704), (828, 702)]]\n"
     ]
    }
   ],
   "source": [
    "def transform_key_points_list_2_list_of_tubels(key_points_list):\n",
    "    counter=0\n",
    "    x=0\n",
    "    y=0\n",
    "    tupel=(x,y)\n",
    "    list_out=[]\n",
    "    for i in range(0,len(key_points_list),2):\n",
    "        x=key_points_list[i]\n",
    "        y=key_points_list[i+1]\n",
    "        tupel=(x,y)\n",
    "        list_out.append(tupel)\n",
    "    return list_out\n",
    "key_point_list_of_tubels=[]\n",
    "for key_points_list_singel_list in key_points_list:\n",
    "    key_point_list_of_tubels.append(transform_key_points_list_2_list_of_tubels(key_points_list_singel_list))\n",
    "print(key_point_list_of_tubels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0deeab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0,\n",
       "  array([[     1539.1],\n",
       "         [     855.44],\n",
       "         [     6784.1]])),\n",
       " (1.0,\n",
       "  array([[    -3117.9],\n",
       "         [     867.23],\n",
       "         [     7368.4]])),\n",
       " (0.0,\n",
       "  array([[     1065.9],\n",
       "         [     564.65],\n",
       "         [      14673]])),\n",
       " (1.0,\n",
       "  array([[    -3247.9],\n",
       "         [     616.46],\n",
       "         [      15933]]))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_3D = np.array([\n",
    " \n",
    "                      (0.0, 0.0, 0.0),       #top\n",
    " \n",
    "                      (-6.0, -107.0,0.0),  #mid_L_top\n",
    " \n",
    "                      (6.0, -107.0, 0.0),#mid_R_top\n",
    " \n",
    "                      (-58.0, -214.0, 0.0), #mid_L_bot\n",
    " \n",
    "                      (58.0, -214.0, 0.0),#mid_R_bot\n",
    " \n",
    "                      (-110.0, -321.0, 0.0) #bot_L \n",
    " \n",
    "                      ,(110.0, -321.0, 0.0) #bot_R \n",
    " \n",
    "                     ])\n",
    "\n",
    "fx=1400\n",
    "fy=1400\n",
    "cx=1104\n",
    "cy=621\n",
    "k1=0\n",
    "k2=0\n",
    "p1=0\n",
    "p2=0\n",
    "k3=0\n",
    "\n",
    "distortion_coeffs = np.zeros((4,1))\n",
    "#focal_length = size[1]\n",
    "#center = (size[1]/2, size[0]/2)\n",
    "matrix_camera = np.array(\n",
    "                         [[fx, 0, cx],\n",
    "                         [0, fy, cy],\n",
    "                         [0, 0, 1] ], dtype = \"double\"\n",
    "                         )\n",
    "\n",
    "distortion_coeffs[0]=k1\n",
    "distortion_coeffs[1]=k2\n",
    "prescription_output=[]\n",
    "counter=0\n",
    "for singel_cone_tubels in key_point_list_of_tubels:\n",
    "    \n",
    "    image_points_2D= np.array(singel_cone_tubels, dtype=\"double\")\n",
    "    success, vector_rotation, vector_translation = cv2.solvePnP(points_3D, image_points_2D, matrix_camera, distortion_coeffs, flags=0)\n",
    "    if success:\n",
    "           prescription_output.append((cones_labels[counter],vector_translation))\n",
    "    counter=counter+1\n",
    "\n",
    "prescription_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393232e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e806fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6a99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d87836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66863912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d42ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede673ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d794c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019955e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f32c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac5215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73ef0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
